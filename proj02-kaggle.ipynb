{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:42:54.402984Z",
     "iopub.status.busy": "2023-01-20T16:42:54.402067Z",
     "iopub.status.idle": "2023-01-20T16:42:56.819178Z",
     "shell.execute_reply": "2023-01-20T16:42:56.817890Z",
     "shell.execute_reply.started": "2023-01-20T16:42:54.402934Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n",
    "# File management\n",
    "import os\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# Import relevant libraries\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Rescaling\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:42:56.821581Z",
     "iopub.status.busy": "2023-01-20T16:42:56.821179Z",
     "iopub.status.idle": "2023-01-20T16:42:56.844178Z",
     "shell.execute_reply": "2023-01-20T16:42:56.843133Z",
     "shell.execute_reply.started": "2023-01-20T16:42:56.821550Z"
    }
   },
   "outputs": [],
   "source": [
    "# important functions\n",
    "# split the data to improve debug performance\n",
    "def get_sample_dataset(dataset, percentage):\n",
    "    size = int(dataset.cardinality().numpy())\n",
    "    \n",
    "    # Specify seed to always have the same split distribution between runs\n",
    "    dataset = dataset.shuffle(size, seed=12)\n",
    "    \n",
    "    sample_size = int(percentage*size)\n",
    "    sample = dataset.take(sample_size)\n",
    "    return sample\n",
    "\n",
    "def convert_to_numpy(dataset):\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for image, label in dataset.as_numpy_iterator():\n",
    "        X.append(image.astype(\"uint8\"))\n",
    "        y.append(label.astype(\"uint8\")[0])\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y\n",
    "\n",
    "def show_bar_chart(dataset, name):\n",
    "    outputs = dataset.map(lambda x,y: y)\n",
    "    labels = np.asarray([y[0] for y in outputs.as_numpy_iterator()])\n",
    "    labels = [classes[i] for i in labels]\n",
    "    plt.figure(figsize = (15,8))\n",
    "    sns.countplot(labels)\n",
    "    plt.title(f\"Frequency of each label({name})\")\n",
    "    plt.show()\n",
    "    \n",
    "# split data\n",
    "# https://towardsdatascience.com/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438\n",
    "def get_dataset_partitions_tf(dataset, train_split=0.6, val_split=0.2, test_split=0.2):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    size = int(dataset.cardinality().numpy())\n",
    "    \n",
    "    # Specify seed to always have the same split distribution between runs\n",
    "    dataset = dataset.shuffle(size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * size)\n",
    "    val_size   = int(val_split * size)\n",
    "    \n",
    "    train_ds = dataset.take(train_size)   \n",
    "    val_ds = dataset.skip(train_size).take(val_size)\n",
    "    test_ds = dataset.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def get_img_size(dataset):\n",
    "    return iter(dataset).get_next()[0].numpy().shape[1:]\n",
    "\n",
    "def compile_model(model, optimizer, loss):\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "## visualize loss\n",
    "def show_train_history(hisData,t1,t2): \n",
    "    plt.plot(hisData.history[t1])\n",
    "    plt.plot(hisData.history[t2])\n",
    "    plt.title('Training History')\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend([t1, t2], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def get_output_as_numpy(dataset):\n",
    "    true_y = dataset.map(lambda x,y: y)\n",
    "    return np.asarray([y[0] for y in true_y.as_numpy_iterator()])\n",
    "\n",
    "def evaluate(model, history, dataset):\n",
    "    show_train_history(history, 'loss', 'val_loss')\n",
    "    show_train_history(history, 'accuracy', 'val_accuracy')\n",
    "    \n",
    "    val_x = dataset.map(lambda x,y: x)\n",
    "    \n",
    "    true_y = get_output_as_numpy(dataset)\n",
    "    pred_y = model.predict(dataset)\n",
    "    \n",
    "    pred_y = np.argmax(pred_y, axis=1)\n",
    "    \n",
    "    # get report\n",
    "    report = classification_report(\n",
    "        true_y,\n",
    "        pred_y,\n",
    "    )\n",
    "    \n",
    "    #get confusion matrix\n",
    "    cmatrix = confusion_matrix(\n",
    "        true_y,\n",
    "        pred_y,\n",
    "    )\n",
    "\n",
    "    graph = ConfusionMatrixDisplay(cmatrix)\n",
    "    graph.plot()\n",
    "    plt.show()\n",
    "    print(report)\n",
    "    \n",
    "def test_model(model_func, input_size, epochs, batch_sizes, train_ds, val_ds, test_ds, optimizer, loss):\n",
    "    for batch_size in batch_sizes:\n",
    "        model = sota_model(input_size)\n",
    "        compile_model(model, optimizer, loss)\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=epochs,\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        print(f\"evaluation of the model with batch size: {batch_size}\")\n",
    "        evaluate(model, history, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the dataset \n",
    "Considering the size of the dataset, we will remotely obtain the dataset, from kaggle repository.\n",
    "\n",
    "[Intel Image Classification](https://www.kaggle.com/datasets/puneet6060/intel-image-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:42:56.846443Z",
     "iopub.status.busy": "2023-01-20T16:42:56.845409Z",
     "iopub.status.idle": "2023-01-20T16:43:06.801128Z",
     "shell.execute_reply": "2023-01-20T16:43:06.800088Z",
     "shell.execute_reply.started": "2023-01-20T16:42:56.846403Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/intel-image-classification\"\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"seg_train\", \"seg_train\")\n",
    "test_dir = os.path.join(data_dir, \"seg_test\", \"seg_test\")\n",
    "\n",
    "# load variables\n",
    "label_mode = \"int\"\n",
    "img_size = (150, 150) # original size\n",
    "color_mode='rgb'\n",
    "batch_size=1\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode,\n",
    "    color_mode=color_mode,\n",
    "    image_size=img_size,\n",
    "    validation_split=0.2,\n",
    "    seed=123,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode,\n",
    "    color_mode=color_mode,\n",
    "    image_size=img_size,\n",
    "    validation_split=0.2,\n",
    "    seed=123,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode,\n",
    "    color_mode=color_mode,\n",
    "    image_size=img_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "classes = test_ds.class_names\n",
    "print(classes)\n",
    "\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    train_ds.shuffle(train_ds.cardinality(),seed=12)\n",
    "    train_ds = train_ds.take(1200)\n",
    "    val_ds.shuffle(val_ds.cardinality(),seed=12)\n",
    "    val_ds = val_ds.take(400)\n",
    "    test_ds.shuffle(test_ds.cardinality(),seed=12)\n",
    "    test_ds = test_ds.take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:06.804058Z",
     "iopub.status.busy": "2023-01-20T16:43:06.803220Z",
     "iopub.status.idle": "2023-01-20T16:43:06.901719Z",
     "shell.execute_reply": "2023-01-20T16:43:06.899992Z",
     "shell.execute_reply.started": "2023-01-20T16:43:06.803999Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize image\n",
    "normalization = Rescaling(1.0/255)\n",
    "norm_train_ds = train_ds.map(lambda x,y: (normalization(x), y))\n",
    "norm_val_ds = val_ds.map(lambda x,y: (normalization(x), y))\n",
    "norm_test_ds = test_ds.map(lambda x,y: (normalization(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:06.903934Z",
     "iopub.status.busy": "2023-01-20T16:43:06.903498Z",
     "iopub.status.idle": "2023-01-20T16:43:07.828884Z",
     "shell.execute_reply": "2023-01-20T16:43:07.827399Z",
     "shell.execute_reply.started": "2023-01-20T16:43:06.903887Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(10,10))\n",
    "axes = axes.flatten()\n",
    "it = iter(train_ds)\n",
    "\n",
    "for i in range(9):    \n",
    "    elem = it.get_next()\n",
    "    image = elem[0].numpy()[0].astype(\"uint8\")\n",
    "    label = np.argmax(elem[1].numpy())\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(classes[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:07.830798Z",
     "iopub.status.busy": "2023-01-20T16:43:07.830415Z",
     "iopub.status.idle": "2023-01-20T16:43:12.083307Z",
     "shell.execute_reply": "2023-01-20T16:43:12.081848Z",
     "shell.execute_reply.started": "2023-01-20T16:43:07.830766Z"
    }
   },
   "outputs": [],
   "source": [
    "# get frequency for each subset\n",
    "show_bar_chart(train_ds, \"training\")\n",
    "show_bar_chart(val_ds, \"validation\")\n",
    "show_bar_chart(test_ds, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.085599Z",
     "iopub.status.busy": "2023-01-20T16:43:12.085163Z",
     "iopub.status.idle": "2023-01-20T16:43:12.123712Z",
     "shell.execute_reply": "2023-01-20T16:43:12.122423Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.085565Z"
    }
   },
   "outputs": [],
   "source": [
    "# get images size\n",
    "# It is too heavy to keep repeating this instruction\n",
    "input_size = get_img_size(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.125892Z",
     "iopub.status.busy": "2023-01-20T16:43:12.125443Z",
     "iopub.status.idle": "2023-01-20T16:43:12.131786Z",
     "shell.execute_reply": "2023-01-20T16:43:12.130344Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.125855Z"
    }
   },
   "outputs": [],
   "source": [
    "# get batch_sizes\n",
    "batch_sizes = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.135103Z",
     "iopub.status.busy": "2023-01-20T16:43:12.133905Z",
     "iopub.status.idle": "2023-01-20T16:43:12.143385Z",
     "shell.execute_reply": "2023-01-20T16:43:12.142010Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.135026Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model number 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.147115Z",
     "iopub.status.busy": "2023-01-20T16:43:12.146689Z",
     "iopub.status.idle": "2023-01-20T16:43:12.158115Z",
     "shell.execute_reply": "2023-01-20T16:43:12.156445Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.147074Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basic_model01(input_size):\n",
    "    X_input = Input(input_size, name=\"input\")\n",
    "    \n",
    "    # Rescale image to range [0,1]\n",
    "    X = Rescaling(1.0/255)(X_input)\n",
    "    \n",
    "    # Conv01\n",
    "    X = Conv2D(32, (3, 3), activation='relu', name = 'conv01_32-3')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool01')(X)\n",
    "    \n",
    "    # Conv02\n",
    "    X = Conv2D(64, (3, 3), activation='relu', name = 'conv02_64-3')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool02')(X)\n",
    "    \n",
    "    # Conv03\n",
    "    X = Conv2D(128, (3, 3), activation='relu', name = 'conv03_128-3')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool03')(X)\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #FC01\n",
    "    X = Dense(64, activation='relu', name = 'FC01_64_relu')(X)\n",
    "    \n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\", name = 'softmax_6')(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = X_input, outputs = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.160255Z",
     "iopub.status.busy": "2023-01-20T16:43:12.159826Z",
     "iopub.status.idle": "2023-01-20T16:43:12.172792Z",
     "shell.execute_reply": "2023-01-20T16:43:12.171334Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.160219Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_model02(input_size):\n",
    "    X_input = Input(input_size)\n",
    "    \n",
    "    # Rescale image to range [0,1]\n",
    "    X = Rescaling(1.0/255)(X_input)\n",
    "    \n",
    "    # Conv01\n",
    "    X = Conv2D(32, (3, 3), activation='relu', name = 'conv01')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool01')(X)\n",
    "    \n",
    "    # Conv02\n",
    "    X = Conv2D(64, (3, 3), activation='relu', name = 'conv02')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool02')(X)\n",
    "    \n",
    "    # Conv03\n",
    "    X = Conv2D(128, (3, 3), activation='relu', name = 'conv03')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool03')(X)\n",
    "\n",
    "    # Conv04\n",
    "    X = Conv2D(256, (3, 3), activation='relu', name = 'conv04')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool04')(X)\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #FC01\n",
    "    X = Dense(64, activation='relu', name = 'FC01')(X)\n",
    "    \n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\", name = 'output')(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = X_input, outputs = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.175811Z",
     "iopub.status.busy": "2023-01-20T16:43:12.174872Z",
     "iopub.status.idle": "2023-01-20T16:43:12.191624Z",
     "shell.execute_reply": "2023-01-20T16:43:12.190575Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.175756Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_model03(input_size):\n",
    "    X_input = Input(input_size)\n",
    "    \n",
    "    # Rescale image to range [0,1]\n",
    "    X = Rescaling(1.0/255)(X_input)\n",
    "    \n",
    "    # block 01\n",
    "    X = Conv2D(32, (3, 3), activation='relu', name = 'b1_conv1')(X)\n",
    "    X = Conv2D(32, (3, 3), activation='relu', name = 'b1_conv2')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool01')(X)\n",
    "    \n",
    "    # Conv02\n",
    "    X = Conv2D(64, (3, 3), activation='relu', name = 'b2_conv1')(X)\n",
    "    X = Conv2D(64, (3, 3), activation='relu', name = 'b2_conv2')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool02')(X)\n",
    "    \n",
    "    # Conv03\n",
    "    X = Conv2D(128, (3, 3), activation='relu', name = 'b3_conv1')(X)\n",
    "    X = Conv2D(128, (3, 3), activation='relu', name = 'b3_conv2')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool03')(X)\n",
    "\n",
    "    # Conv04\n",
    "    X = Conv2D(256, (3, 3), activation='relu', name = 'b4_conv1')(X)\n",
    "    X = Conv2D(256, (3, 3), activation='relu', name = 'b4_conv2')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool04')(X)\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #FC01\n",
    "    X = Dense(128, activation='relu', name = 'FC01')(X)\n",
    "    \n",
    "    #FC02\n",
    "    X = Dense(128, activation='relu', name = 'FC02')(X)\n",
    "    \n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\", name = 'output')(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = X_input, outputs = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.194318Z",
     "iopub.status.busy": "2023-01-20T16:43:12.193414Z",
     "iopub.status.idle": "2023-01-20T16:43:12.209823Z",
     "shell.execute_reply": "2023-01-20T16:43:12.208688Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.194275Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_model04(input_size):\n",
    "    X_input = Input(input_size)\n",
    "    \n",
    "    # Rescale image to range [0,1]\n",
    "    X = Rescaling(1.0/255)(X_input)\n",
    "    \n",
    "    # block 01\n",
    "    X = Conv2D(32, (3, 3), name = 'b1_conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b1_bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(32, (3, 3), name = 'b1_conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b1_bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool01')(X)\n",
    "    \n",
    "    # Conv02\n",
    "    X = Conv2D(64, (3, 3), name = 'b2_conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b2_bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), name = 'b2_conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b2_bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool02')(X)\n",
    "    \n",
    "    # Conv03\n",
    "    X = Conv2D(128, (3, 3), name = 'b3_conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b3_bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(128, (3, 3), name = 'b3_conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b3_bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool03')(X)\n",
    "\n",
    "    # Conv04\n",
    "    X = Conv2D(256, (3, 3), name = 'b4_conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b4_bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(256, (3, 3), name = 'b4_conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'b4_bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool04')(X)\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #FC01\n",
    "    X = Dense(128, activation='relu', name = 'FC01')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    #FC02\n",
    "    X = Dense(128, activation='relu', name = 'FC02')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\", name = 'output')(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = X_input, outputs = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art Model - VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.212344Z",
     "iopub.status.busy": "2023-01-20T16:43:12.211614Z",
     "iopub.status.idle": "2023-01-20T16:43:12.226957Z",
     "shell.execute_reply": "2023-01-20T16:43:12.225933Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.212305Z"
    }
   },
   "outputs": [],
   "source": [
    "def sota_model(input_size):\n",
    "    \n",
    "    vgg16 = VGG16(\n",
    "        input_shape=input_size,\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "    )\n",
    "    vgg16.trainable = False\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(vgg16.output)\n",
    "\n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\", name = 'output')(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = vgg16.input, outputs = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.229143Z",
     "iopub.status.busy": "2023-01-20T16:43:12.228552Z",
     "iopub.status.idle": "2023-01-20T16:43:12.244931Z",
     "shell.execute_reply": "2023-01-20T16:43:12.243647Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.229107Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_model(input_size):\n",
    "    X_input = Input(input_size)\n",
    "    \n",
    "    X = Rescaling(1.0/255)(X_input)\n",
    "\n",
    "    # Conv01\n",
    "    X = Conv2D(32, (3, 3), strides=(1,1), padding='same' )(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    \n",
    "    # Conv02\n",
    "    X = Conv2D(32, (3, 3), strides=(1,1), padding='same' )(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    \n",
    "    # Conv03\n",
    "    X = Conv2D(32, (3, 3), strides=(1,1), padding='same' )(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    \n",
    "    # Conv04\n",
    "    X = Conv2D(32, (3, 3), strides=(1,1), padding='same' )(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((2, 2))(X)\n",
    "    \n",
    "    #Flatten\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = Dense(128, activation='relu')(X)\n",
    "\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Output\n",
    "    X = Dense(len(classes), activation=\"softmax\")(X)\n",
    "    \n",
    "    #create\n",
    "    return Model(inputs = X_input, outputs = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T16:43:12.247572Z",
     "iopub.status.busy": "2023-01-20T16:43:12.246884Z",
     "iopub.status.idle": "2023-01-20T16:43:58.282597Z",
     "shell.execute_reply": "2023-01-20T16:43:58.281263Z",
     "shell.execute_reply.started": "2023-01-20T16:43:12.247531Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = \"sparse_categorical_crossentropy\"\n",
    "optimizer = \"adam\"\n",
    "batch_size = 256\n",
    "\n",
    "final_model = final_model(input_size)\n",
    "compile_model(final_model, optimizer, loss)\n",
    "history = final_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "evaluate(final_model, history, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

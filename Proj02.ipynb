{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa58f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 18:30:02.395570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n",
    "# File management\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Import relevant libraries\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Rescaling\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c760a0",
   "metadata": {},
   "source": [
    "## Obtain the dataset \n",
    "Considering the size of the dataset, we will remotely obtain the dataset, from kaggle repository.\n",
    "\n",
    "[Intel Image Classification](https://www.kaggle.com/datasets/puneet6060/intel-image-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d3dd1",
   "metadata": {},
   "source": [
    "## Install Kaggle and set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87552085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                             title                                         size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "--------------------------------------------------------------  -------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "ahsan81/hotel-reservations-classification-dataset               Hotel Reservations Dataset                   480KB  2023-01-04 12:50:31           2112         86  1.0              \n",
      "thedevastator/global-fossil-co2-emissions-by-country-2002-2022  Emissions by Country, 2002-2022              621KB  2023-01-02 20:10:36           1147         42  1.0              \n",
      "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset          7KB  2022-12-18 22:51:11           5501        177  1.0              \n",
      "rakkesharv/spotify-top-10000-streamed-songs                     Spotify Top 10000 Streamed Songs             280KB  2023-01-02 08:17:15           1072         41  1.0              \n",
      "meirnizri/covid19-dataset                                       COVID-19 Dataset                               5MB  2022-11-13 15:47:17          18185        496  1.0              \n",
      "omkargowda/suicide-rates-overview-1985-to-2021                  Suicide Rates Overview (1985 to 2021)        539KB  2023-01-04 15:11:45            851         38  1.0              \n",
      "devrimtuner/list-of-cities-proper-by-population-density         List of cities proper by population density    3KB  2023-01-05 09:08:19            771         35  0.9411765        \n",
      "thedevastator/analyzing-credit-card-spending-habits-in-india    Credit Card Spending Habits in India         319KB  2022-12-14 07:30:37           2994         82  1.0              \n",
      "ahsan81/superstore-marketing-campaign-dataset                   Superstore Marketing Campaign Dataset         55KB  2023-01-02 19:25:08           1179         38  1.0              \n",
      "devrimtuner/list-of-moststreamed-songs-on-spotify               Top 100 Spotify SongsðŸ‘‘ðŸŽ¤ðŸŽ§ðŸŽ¼                      3KB  2022-12-30 05:42:54           1095         46  1.0              \n",
      "devrimtuner/top-100-video-games                                 Top 50 Video Games                             2KB  2022-12-30 06:06:16            584         27  1.0              \n",
      "devrimtuner/top-100list-of-bestselling-mobile-phones            (TOP 100)List of best-selling mobile phones    2KB  2022-12-30 07:23:56            595         35  0.9411765        \n",
      "michals22/coffee-dataset                                        Coffee dataset                                24KB  2022-12-15 20:02:12           5185        110  1.0              \n",
      "parasharmanas/global-hunger-index-2022-trends                   Global Hunger Index 2022 Trends                3KB  2022-12-28 13:37:11            630         26  1.0              \n",
      "arvindnagaonkar/power-generation-data                           Daily Power Generation Data                   15MB  2022-12-23 18:09:56           1127         28  0.9705882        \n",
      "aklimarimi/qs-world-ranked-universities-20182022                QS World ranked Universities (2018-2022)      51KB  2022-12-28 03:53:39           1059         48  1.0              \n",
      "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                       6MB  2022-12-03 09:27:17           4699         97  1.0              \n",
      "devrimtuner/top-50list-of-most-expensive-films                  (TOP 50)List of most expensive films ðŸŽ¬ðŸŽ¬ðŸ†ðŸ¥‡ðŸ¥ˆðŸ¥‰    2KB  2022-12-31 01:31:08            705         32  0.9411765        \n",
      "rajeshrampure/black-friday-sale                                 Black Friday Sale                              5MB  2022-12-24 09:37:49           1651         42  1.0              \n",
      "dansbecker/melbourne-housing-snapshot                           Melbourne Housing Snapshot                   451KB  2018-06-05 12:52:24         104228       1194  0.7058824        \n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/general/74235\n",
    "# Install Kaggle\n",
    "!pip install -q kaggle\n",
    "# create folder ~/.kaggle, which is where kaggle will search for the API Token\n",
    "!rm -r ~/.kaggle\n",
    "!mkdir ~/.kaggle\n",
    "# move kaggle.json to ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "# Change the permissions of the file. \n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "# Check if it is working\n",
    "!kaggle datasets list\n",
    "\n",
    "repository_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa4f91",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7d033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/renan/Documents/GitHub/FAA_P02\n"
     ]
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "zip_file = 'intel-image-classification.zip'\n",
    "tmp_dir = \"dataset\"\n",
    "\n",
    "data_dir = os.path.join(repository_dir, tmp_dir)\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"create dataset directory\")\n",
    "    os.mkdir(data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    print(os.getcwd())\n",
    "    os.system(\"kaggle datasets download -d puneet6060/intel-image-classification\")\n",
    "    zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
    "    zip_ref.extractall(data_dir)\n",
    "    zip_ref.close()\n",
    "    os.remove(os.path.join(data_dir, zip_file))\n",
    "    \n",
    "train_dir = os.path.join(data_dir, \"seg_train\", \"seg_train\")\n",
    "test_dir = os.path.join(data_dir, \"seg_test\", \"seg_test\")\n",
    "\n",
    "os.chdir(repository_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561bdf",
   "metadata": {},
   "source": [
    "## Loading the images\n",
    "**Note**: Only load this example for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737ed08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation_percentage = 0.2\n",
    "\n",
    "data_train, data_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=None,\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=validation_percentage,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "data_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=None,\n",
    "    label_mode=\"categorical\",\n",
    ")\n",
    "class_names = data_train.class_names\n",
    "print(class_names)\n",
    "\n",
    "for image, label in data_train.take(1).as_numpy_iterator():\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c177ed6",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c29b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from https://www.tensorflow.org/tutorials/load_data/images\n",
    "import matplotlib.pyplot as plt\n",
    "subset = list(data_train.take(9).as_numpy_iterator())\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10,10))\n",
    "axes = axes.flatten()\n",
    "for i in range(9):\n",
    "    ax = axes[i]\n",
    "    img, label = subset[i]\n",
    "    label = label.astype(\"uint8\")\n",
    "    label = np.where(label == 1)[0][0]\n",
    "    ax.imshow(img.astype(\"uint8\"))\n",
    "    ax.set_title(class_names[label])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e61691",
   "metadata": {},
   "source": [
    "## Model number 01 - VGG-16\n",
    "The VGG-16 is one of the most popular pre-trained models for image classification. Introduced in the famous \n",
    "ILSVRC 2014 Conference, it was and remains THE model to beat even today. Developed at the Visual Graphics \n",
    "Group at the University of Oxford, VGG-16 beat the then standard of AlexNet and was quickly adopted by \n",
    "researchers and the industry for their image Classification Tasks.\n",
    "https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83fda2",
   "metadata": {},
   "source": [
    "trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d767d5b",
   "metadata": {},
   "source": [
    "## Reload Image\n",
    "img_size = (224, 224)\n",
    "No necessary augmenting data besides image resizing and rescale normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f8675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Using 11228 files for training.\n",
      "Using 2806 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 18:30:19.100544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-15 18:30:19.101688: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 6 classes.\n",
      "image shape: (224, 224, 3)\n",
      "2\n",
      "min value: 14.34375\n",
      "max value: 255.0\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "validation_percentage = 0.2\n",
    "# Categorical to be able to use category_cross_entropy loss\n",
    "label_mode = \"int\"\n",
    "\n",
    "data_train_vgg16, data_val_vgg16 = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=None,\n",
    "    label_mode=label_mode,\n",
    "    color_mode='rgb',\n",
    "    image_size=(img_width, img_height),\n",
    "    validation_split=validation_percentage,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "data_test_vgg16 = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=None,\n",
    "    label_mode=label_mode,\n",
    "    color_mode='rgb',\n",
    "    image_size=(img_width, img_height),\n",
    ")\n",
    "\n",
    "for image, label in data_train_vgg16.take(1).as_numpy_iterator():\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    print(label)\n",
    "    print(f\"min value: {np.min(image)}\")\n",
    "    print(f\"max value: {np.max(image)}\")\n",
    "    \n",
    "class_names = data_train_vgg16.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93429115",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "rescaling = 1.0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9840afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (224, 224, 3)\n",
      "3\n",
      "min value: 0.0\n",
      "max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "data_train_vgg16 = data_train_vgg16.map(lambda x,y: (normalization_layer(x), y))\n",
    "\n",
    "for image, label in data_train_vgg16.take(1).as_numpy_iterator():\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    print(label)\n",
    "    print(f\"min value: {np.min(image)}\")\n",
    "    print(f\"max value: {np.max(image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae30f4c",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62cfcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG16(\n",
    "    input_shape=(224, 224, 3), # Shape of our images\n",
    "    include_top = False, # Leave out the last fully connected layer\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "# we do not train the parameters\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2f2016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765\n",
    "# FC layer very simple and with a softmax activation unit\n",
    "x = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "landscapeModel01 = Model(inputs=base_model.input, outputs=x, name=\"landscapeModel01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bdeac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"landscapeModel01\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 150534    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,865,222\n",
      "Trainable params: 150,534\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss = \"sparse_categorical_crossentropy\" #Unvariable, considering the data phenomenum\n",
    "optimizer = \"adam\" # Variable\n",
    "\n",
    "landscapeModel01.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=loss,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "landscapeModel01.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a46bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\")\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"landscapeModel01\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(landscapeModel01\u001b[38;5;241m.\u001b[39minput)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlandscapeModel01\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_train_vgg16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_val_vgg16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/faa/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file6b2dq0xo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/renan/anaconda3/envs/faa/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"landscapeModel01\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#fit data\n",
    "shuffle=True # variable\n",
    "epochs=50 # variable, according if it is able to converge\n",
    "batch_size = 200\n",
    "\n",
    "print(landscapeModel01.input)\n",
    "\n",
    "landscapeModel01.fit(\n",
    "    data_train_vgg16,\n",
    "    validation_data=data_val_vgg16,\n",
    "    epochs=epochs,\n",
    "    shuffle=shuffle,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb40c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
